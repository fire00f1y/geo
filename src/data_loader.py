import time
from typing import Sequence, Tuple

import numpy as np
import polars as pl

from util import download_file


def download_amazon_books():
    url = "http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Books.csv"
    output_file_path = "data/amazon_books_ratings.csv"

    return download_file(url, output_file_path, exist_ok=True)


def load_and_process_data(headers: Sequence[str]) -> pl.DataFrame or None:
    print("ğŸš€ Starting Amazon Books dataset loading...")

    # Download dataset
    file_path = download_amazon_books()
    if not file_path:
        return None

    print("\nğŸ“Š Loading and analyzing dataset...")
    # Load data with proper column names
    df = pl.read_csv(file_path, has_header=False)
    df = df.rename({old: new for old, new in zip(df.columns, headers)})

    print(f"âœ“ Raw dataset loaded:")
    print(f"  â€¢ Shape: {df.shape}")
    print(f"  â€¢ Users: {df['user_id'].n_unique():,}")
    print(f"  â€¢ Books: {df['book_id'].n_unique():,}")
    print(f"  â€¢ Interactions: {len(df):,}")
    print(f"  â€¢ Sparsity: {(1 - len(df) / (df['user_id'].n_unique() * df['book_id'].n_unique())) * 100:.2f}%")

    # Basic data quality check
    print(f"\nğŸ” Data quality check:")
    print(f"  â€¢ Missing values: {df.null_count().to_series().sum()}")
    print(f"  â€¢ Rating range: {df['rating'].min()} - {df['rating'].max()}")
    print(f"  â€¢ Rating distribution:\n{df['rating'].value_counts(sort=False).sort('rating')}")

    return df


if __name__ == "__main__":
    start = time.time()
    columns = ['user_id', 'book_id', 'rating', 'timestamp']
    full_data = load_and_process_data(columns)
    print(f"Dataset loading and sample created in {time.time() - start:.2f} seconds.")

    if full_data is not None:
        print("\nğŸ¯ Dataset ready for GNN model development!")
    else:
        print("âŒ Dataset loading failed")